{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'multipl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4344/545707957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mimg_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mimage_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'multipl'"
     ]
    }
   ],
   "source": [
    "p = Path(r'C:\\Users\\gaura\\Pictures\\PV-Module-Fault-Detection\\data')\n",
    "\n",
    "labels_dict = {\"multiple\":0,\"single\":1,\"straight\":2}\n",
    "labels=[]\n",
    "image_data=[] \n",
    "\n",
    "for folder_name in p.glob(\"*\"):\n",
    "    label=str(folder_name).split(\"\\\\\")[-1][:-1]\n",
    "    \n",
    "    for image_path in folder_name.glob(\"*.png\"):\n",
    "        img=image.load_img(image_path,target_size=(32,32))\n",
    "        img_array=image.img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "        labels.append(labels_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert data into numpy array\n",
    "\n",
    "image_data = np.array(image_data, dtype='float32')/255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(image_data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly shuffle data\n",
    "\n",
    "import random \n",
    "combined = list(zip(image_data, labels))\n",
    "random.shuffle(combined)\n",
    "\n",
    "image_data[:], labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the data\n",
    "\n",
    "def drawImg(img):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "for i in range(10):\n",
    "    drawImg(image_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C=1.0):\n",
    "        self.C = C\n",
    "        self.W = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def hingeLoss(self,W,b,X,Y):\n",
    "        loss  = 0.0\n",
    "        \n",
    "        loss += .5*np.dot(W,W.T)\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for i in range(m):\n",
    "            ti = Y[i]*(np.dot(W,X[i].T)+b)\n",
    "            loss += self.C *max(0,(1-ti))\n",
    "            \n",
    "        return loss[0][0]\n",
    "    \n",
    "    def fit(self,X,Y,batch_size=50,learning_rate=0.001,maxItr=500):\n",
    "        \n",
    "        no_of_features = X.shape[1]\n",
    "        no_of_samples = X.shape[0]\n",
    "        \n",
    "        n = learning_rate\n",
    "        c = self.C\n",
    "        \n",
    "        #Init the model parameters\n",
    "        W = np.zeros((1,no_of_features))\n",
    "        bias = 0\n",
    "        \n",
    "        #Initial Loss\n",
    "        \n",
    "        #Training from here...\n",
    "        # Weight and Bias update rule\n",
    "        losses = []\n",
    "        \n",
    "        for i in range(maxItr):\n",
    "            #Training Loop\n",
    "            \n",
    "            l = self.hingeLoss(W,bias,X,Y)\n",
    "            losses.append(l)\n",
    "            ids = np.arange(no_of_samples)\n",
    "            np.random.shuffle(ids)\n",
    "            \n",
    "            #Batch Gradient Descent(Paper) with random shuffling\n",
    "            for batch_start in range(0,no_of_samples,batch_size):\n",
    "                #Assume 0 gradient for the batch\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "                \n",
    "                #Iterate over all examples in the mini batch\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<no_of_samples:\n",
    "                        i = ids[j]\n",
    "                        ti =  Y[i]*(np.dot(W,X[i].T)+bias)\n",
    "                        \n",
    "                        if ti>1:\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            gradw += c*Y[i]*X[i]\n",
    "                            gradb += c*Y[i]\n",
    "                            \n",
    "                #Gradient for the batch is ready! Update W,B\n",
    "                W = W - n*W + n*gradw\n",
    "                bias = bias + n*gradb\n",
    "                \n",
    "        \n",
    "        self.W = W\n",
    "        self.b = bias\n",
    "        return W,bias,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data conversion for One vs One classification\n",
    "\n",
    "M = image_data.shape[0]\n",
    "image_data = image_data.reshape(M,-1)\n",
    "print(image_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classWiseData(x, y):\n",
    "    data = {}\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        data[i] = []\n",
    "        \n",
    "    for i in range(x.shape[0]):\n",
    "        data[y[i]].append(x[i])\n",
    "        \n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = classWiseData(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0].shape[0])\n",
    "print(data[1].shape[0])\n",
    "print(data[2].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combines data of two classes into a single matrix\"\"\"\n",
    "def getDataPairForSVM(d1,d2):\n",
    "    \n",
    "    l1,l2 = d1.shape[0], d2.shape[0]\n",
    "    samples = l1+l2\n",
    "    features = d1.shape[1]\n",
    "    \n",
    "    data_pair = np.zeros((samples,features))\n",
    "    data_labels = np.zeros((samples,))\n",
    "    \n",
    "    data_pair[:l1,:] = d1\n",
    "    data_pair[l1:,:] = d2\n",
    "    \n",
    "    data_labels[:l1] = -1\n",
    "    data_labels[l1:] = 1\n",
    "    \n",
    "    return data_pair, data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training nC2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySVM = SVM()\n",
    "xp, yp = getDataPairForSVM(data[0], data[1])\n",
    "w,b,loss = mySVM.fit(xp,yp,learning_rate=0.00001,maxItr=1000)\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVMs(x,y):\n",
    "    svm_classifiers = {}\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        svm_classifiers[i] = {}\n",
    "        for j in range(i+1, number_of_classes):\n",
    "            xpair,ypair = getDataPairForSVM(data[i],data[j])\n",
    "            wts,b,loss = mySVM.fit(xpair, ypair,learning_rate=0.00001,maxItr=1000)\n",
    "            svm_classifiers[i][j] = (wts,b)\n",
    "            \n",
    "            plt.plot(loss)\n",
    "            plt.show()\n",
    "            \n",
    "    return svm_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifiers = trainSVMs(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_dogs = svm_classifiers[0][1]\n",
    "cats_humans = svm_classifiers[0][3]\n",
    "print(cats_dogs[0].shape)\n",
    "print(cats_dogs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryPredict(x,w,b):\n",
    "    z = np.dot(x,w.T) + b\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    \n",
    "    count = np.zeros((number_of_classes,))\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        for j in range(i+1, number_of_classes):\n",
    "            w,b = svm_classifiers[i][j]\n",
    "            \n",
    "            #Take a majority prediction\n",
    "            z = binaryPredict(x,w,b)\n",
    "            \n",
    "            if z==1:\n",
    "                count[j] += 1\n",
    "            else:\n",
    "                count[i] += 1\n",
    "    \n",
    "    final_prediction = np.argmax(count)\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(image_data[0]))\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x,y):\n",
    "    \n",
    "    pred = []\n",
    "    count=0\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        prediction = predict(x[i])\n",
    "        pred.append(prediction)\n",
    "        if prediction==y[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return count/x.shape[0], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, ypred = accuracy(image_data, labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(image_data, labels)\n",
    "ypred_sklearn = svm_classifier.predict(image_data)\n",
    "svm_classifier.score(image_data,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use this method directly - \"\"\"\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(labels, ypred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_matrix, [0,1,2,3],normalize=False,title='Confusion matrix',cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sci-kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_sklearn = confusion_matrix(labels, ypred_sklearn)\n",
    "print(cnf_matrix_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_matrix_sklearn, [0,1,2,3],normalize=False,title='Confusion matrix',cmap=plt.cm.Blues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
